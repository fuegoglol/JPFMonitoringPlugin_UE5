from unittest.mock import DEFAULT

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys

from pandas.core.construction import sanitize_array
from scipy.stats import zscore

DEFAULT_ROLLING_WINDOW = 5


def sanitize_data(data, z_threshold=3):
    """
    Sanitizes the dataset by:
      - Removing rows with missing values for 'Time', 'Power', or 'FPS'.
      - Removing rows where FPS is non-positive (to prevent division by zero).
      - Removing rows where the 'Power' or 'FPS' columns have a z-score greater than the threshold.
    Note: The 'Time' column is not checked for outliers as it serves as the key.
    """
    initial_count = len(data)

    # Remove rows with missing values for the key columns
    data = data.dropna(subset=['Time', ' Power', ' FPS'])

    # Remove rows with non-positive FPS (to prevent division by zero)
    data = data[data[' FPS'] > 0]

    # Compute z-scores for 'Power' and 'FPS' only
    numeric_cols = [' Power', ' FPS']
    z_scores = np.abs(zscore(data[numeric_cols]))

    # Keep only rows where all z-scores are below the threshold
    data = data[(z_scores < z_threshold).all(axis=1)]

    final_count = len(data)

    if final_count < initial_count:
        print(f"Sanitized dataset: removed {initial_count - final_count} of {initial_count} rows.")

    return data


def main(path, csv_data, rolling_window=DEFAULT_ROLLING_WINDOW):

    # /!\ WARNING: in this code, we assume that the csv file has been generated by the JPFMonitoringPlugin
    # and that's why we expect columns power and fps to be preceded by a space.

    # Check that required columns exist
    required_columns = {"Time", " Power", " FPS"}

    if not required_columns.issubset(csv_data.columns):
        print(f"CSV file must contain the columns: {required_columns}")
        return

    # Sanitize the data
    data = sanitize_data(csv_data)
    if data.empty:
        print("No data left after sanitization. Please check the input CSV file.")
        return

    # Compute the ratio (Power / FPS)
    data['Power_per_FPS'] = data[' Power'] / data[' FPS']

    # Add the average of the Power_per_FPS column
    mean = data['Power_per_FPS'].mean()
    for i in range(len(data)):
        data['Mean'] = mean

    # Get the base filename without extension
    base_filename = os.path.splitext(os.path.basename(path))[0]
    output_filename = f"{base_filename}_chart_rw{rolling_window}.png"


    # -------------------------
    # Create the plot
    # -------------------------

    # - Applying rolling window to smooth the data
    # Rolling window of 5, centered around each point
    data['Smoothed'] = data['Power_per_FPS'].rolling(window=rolling_window, center=True).mean()
    # Optionally, fill any NaN values created by the rolling at the edges
    data['Smoothed'] = data['Smoothed'].bfill().ffill()

    # - Creating the plot
    plt.figure(figsize=(10, 6))
    # Plot both the original and the smoothed data for comparison
    plt.plot(data['Time'], data['Power_per_FPS'], label='Joule/Frame (Original)', linewidth=0.5, alpha=0.4)
    plt.plot(data['Time'], data['Smoothed'], label='Joule/Frame (Smoothed)', linewidth=1, color='red')
    plt.plot(data['Time'], data['Mean'], label=f"Mean: {mean:.2f}", linewidth=1, color='orange')
    # empty plot to add the rolling window size to the legend
    plt.plot([], [], ' ', label=f"Rolling Window: {rolling_window}")

    plt.xlabel('Time')
    plt.ylabel('Joule/Frame')
    plt.title(f"{base_filename} - Joule/Frame over Time")
    plt.legend()
    plt.grid(True)

    # Build the output path to the desktop (works on most systems)
    csv_directory = os.path.dirname(os.path.abspath(path))
    output_path = os.path.join(csv_directory, output_filename)

    # Save the figure
    plt.savefig(output_path)
    print(f"Plot saved to {output_path}")


def print_usage():
    print("Usage: python script.py [-rw=<rolling_window_size>] [-d] <path>")
    print("Use 'python script.py -h' for more information.")
    sys.exit(0)


if __name__ == '__main__':
    # Usage examples:
    #   1. Process a single file with a custom rolling window:
    #      python autoplotter_jpf.py -rw=5 path/to/file.csv
    #
    #   2. Process a single file with the default rolling window (see DEFAULT_ROLLING_WINDOW):
    #      python autoplotter_jpf.py path/to/file.csv
    #
    #   3. Process all CSV files in a directory with a custom rolling window:
    #      python autoplotter_jpf.py -rw=5 -d path/to/directory
    #
    #   4. Process all CSV files in a directory with default rolling window:
    #      python autoplotter_jpf.py -d path/to/directory

    # Set default values
    rolling_window = DEFAULT_ROLLING_WINDOW
    is_directory = False

    # Get all arguments (excluding the script name)
    args = sys.argv[1:]
    if not args:
        print("Missing arguments!")
        print("Usage: python script.py [-rw=<rolling_window_size>] [-d] <path>")
        sys.exit(1)


    # Display the help message
    if args[0] == "-h":
        print("Usage: python script.py [-rw=<rolling_window_size>] [-d] <path>")
        print("Options:")
        print("  -rw=<rolling_window_size>  Set the rolling window size (default: 5)")
        print("  -d                         The following path is a directory and all direct CSV files in it will be processed")
        print("Params:")
        print("  <path>                     The path to a CSV file or directory containing CSV files if -d is set")
        sys.exit(0)

    # Check if the first argument is the rolling window flag
    if args[0].startswith("-rw="):
        try:
            rolling_window = int(args[0].split("=")[1])
        except ValueError:
            print("Invalid rolling window size. Must be an integer.")
            print_usage()
            sys.exit(1)

        args = args[1:]

    # Check if the next argument is the directory flag
    if args and args[0] == "-d":
        is_directory = True
        args = args[1:]

    # The remaining argument should be the path
    if not args:
        print("Missing path argument!")
        print_usage()
        sys.exit(1)

    target_path = args[0]

    # Process directory or single file based on the flag
    if is_directory:
        if not os.path.isdir(target_path):
            print(f"Provided path '{target_path}' is not a directory!")
            print_usage()
            sys.exit(1)
        # Process each CSV file in the directory
        for filename in os.listdir(target_path):
            if filename.lower().endswith(".csv"):
                file_path = os.path.join(target_path, filename)
                try:
                    csv_data = pd.read_csv(file_path)
                    main(file_path, csv_data, rolling_window)
                except Exception as e:
                    print(f"Error processing file '{file_path}': {e}")
    else:
        if os.path.isdir(target_path):
            print(f"Provided path '{target_path}' is a directory!\n\tâ†’ Use the -d flag to process directories.")
            print_usage()
            sys.exit(1)
        # Process a single CSV file
        try:
            csv_data = pd.read_csv(target_path)
            main(target_path, csv_data, rolling_window)
        except Exception as e:
            print(f"Error reading the CSV file: {e}")
            sys.exit(1)
