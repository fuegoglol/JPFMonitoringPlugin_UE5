from xmlrpc.client import MAXINT

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys
import csv

from pandas.core.interchange.dataframe_protocol import DataFrame
from scipy.stats import zscore

DEFAULT_ROLLING_WINDOW = 5


def sanitize_data(data, z_threshold=3):
    """
    Sanitizes the dataset by:
      - Removing rows with missing values for 'Time', 'Power', or 'FPS'.
      - Removing rows where FPS is non-positive (to prevent division by zero).
      - Removing rows where the 'Power' or 'FPS' columns have a z-score greater than the threshold.
    Note: The 'Time' column is not checked for outliers as it serves as the key.
    """
    initial_count = len(data)

    # Remove rows with missing values for the key columns
    data = data.dropna(subset=['Time', ' Power', ' FPS'], ignore_index=True)

    # Remove rows with non-positive FPS (to prevent division by zero)
    data = data[data[' FPS'] > 0]

    # Compute z-scores for 'Power' and 'FPS' only
    numeric_cols = [' Power', ' FPS']
    z_scores = np.abs(zscore(data[numeric_cols]))

    # Keep only rows where all z-scores are below the threshold
    data = data[(z_scores < z_threshold).all(axis=1)]

    final_count = len(data)

    if final_count < initial_count:
        print(f"Sanitized dataset: removed {initial_count - final_count} of {initial_count} rows.")

    # Reset the index after removing rows to ensure it is continuous
    return data.reset_index(drop=True)


def get_sanitized_data(csv_data):
    # /!\ WARNING: in this code, we assume that the csv file has been generated by the JPFMonitoringPlugin
    # and that's why we expect columns power and fps to be preceded by a space.

    # Check that required columns exist
    required_columns = {"Time", " Power", " FPS"}

    if not required_columns.issubset(csv_data.columns):
        print(f"CSV file must contain the columns: {required_columns}")
        return

    # Sanitize the data
    data = sanitize_data(csv_data)
    if data.empty:
        print("No data left after sanitization. Please check the input CSV file.")
        return

    return data


def auto_plot(path, csv_data, rolling_window=DEFAULT_ROLLING_WINDOW):
    # get the ratio (Power / FPS)
    data = get_sanitized_data(csv_data)
    data['Power_per_FPS'] = data[' Power'] / data[' FPS']

    # Add the average of the Power_per_FPS column
    mean = data['Power_per_FPS'].mean()
    for i in range(len(data)):
        data['Mean'] = mean

    # Get the base filename without extension
    base_filename = os.path.splitext(os.path.basename(path))[0]
    output_filename = f"{base_filename}_chart_rw{rolling_window}.png"

    # -------------------------
    # Create the plot
    # -------------------------

    # - Applying rolling window to smooth the data
    # Rolling window of 5, centered around each point
    data['Smoothed'] = data['Power_per_FPS'].rolling(window=rolling_window, center=True).mean()
    # Optionally, fill any NaN values created by the rolling at the edges
    data['Smoothed'] = data['Smoothed'].bfill().ffill()

    # - Creating the plot
    plt.figure(figsize=(10, 6))
    # Plot both the original and the smoothed data for comparison
    plt.plot(data['Time'], data['Power_per_FPS'], label='Joule/Frame (Original)', linewidth=0.5, alpha=0.4)
    plt.plot(data['Time'], data['Smoothed'], label='Joule/Frame (Smoothed)', linewidth=1, color='red')
    plt.plot(data['Time'], data['Mean'], label=f"Mean: {mean:.2f}", linewidth=1, color='orange')
    # empty plot to add the rolling window size to the legend
    plt.plot([], [], ' ', label=f"Rolling Window: {rolling_window}")

    plt.xlabel('Time (s)')
    plt.ylabel('Joule/Frame')
    plt.title(f"{base_filename} - Joule/Frame over Time")
    plt.legend()
    plt.grid(True)

    # Build the output path to the desktop (works on most systems)
    csv_directory = os.path.dirname(os.path.abspath(path))
    output_path = os.path.join(csv_directory, output_filename)

    # Save the figure
    plt.savefig(output_path)
    print(f"Plot saved to {output_path}")


def print_usage():
    print("Usage: python auto_plotter.py [-rw=<rolling_window_size>] [-d] <path>")
    print("Use 'python auto_plotter.py -h' for more information.")
    sys.exit(0)


def print_help():
    print(
        "AutoPlotter for JPFMonitoringPlugin is a tool to generate a plot of the 'Joule/FPS' ratio over time from the CSV file generated by the JPFMonitoringPlugin.\n")
    print("Usage: python auto_plotter.py [-rw=<rolling_window_size>] [-d or -b] <path>")
    print("Options:")
    print("  -rw=<rolling_window_size>  Set the rolling window size (default: 5)")
    print(
        "  -d                         The following path is a directory and all direct CSV files in it will be processed")
    print(
        "  -b                         The following path is a directory and all direct CSV files in it will be processed and a unique plot will be generated with min, avg and max values curves + export to a single csv file")
    print("Params:")
    print("  <path>                     The path to a CSV file or directory containing CSV files if -d is set")


def handle_directory(path, rw):
    if not os.path.isdir(path):
        print(f"Provided path '{path}' is not a directory!")
        print_usage()
        sys.exit(1)
    # Process each CSV file in the directory
    for filename in os.listdir(path):
        if filename.lower().endswith(".csv"):
            file_path = os.path.join(path, filename)
            try:
                csv_data = pd.read_csv(file_path)
                auto_plot(file_path, csv_data, rw)
            except Exception as e:
                print(f"Error processing file '{file_path}': {e}")


def handle_single_file(path, rw):
    if os.path.isdir(path):
        print(f"Provided path '{path}' is a directory!\n\tâ†’ Use the -d flag to process directories.")
        print_usage()
        sys.exit(1)
    # Process a single CSV file
    try:
        csv_data = pd.read_csv(path)
        auto_plot(path, csv_data, rw)
    except Exception as e:
        print(f"Error reading the CSV file: {e}")
        sys.exit(1)


def handle_benchmark(path, rw):
    # This function will process all CSV files in the directory <path> and build a unique plot with min, avg and max values curves + export to a single csv file
    if not os.path.isdir(path):
        print(f"Provided path '{path}' is not a directory!")
        print_usage()
        sys.exit(1)

    plot_title = input("Enter the title of the plot: ").strip()

    # context variables
    min_data_len = MAXINT  # length of the csv_data with the least amount of data to ensure that all series have the same length
    min_data_len_index = 0  # index of the csv_data with the least amount of data

    # list all csv files content
    csv_datas = []
    for filename in os.listdir(path):
        if filename.lower().endswith(".csv"):
            file_path = os.path.join(path, filename)
            try:
                csv_data = pd.read_csv(file_path)
                data = get_sanitized_data(csv_data)
                data['Power_per_FPS'] = data[' Power'] / data[' FPS']

                if len(data) < min_data_len:
                    min_data_len = len(data)
                    min_data_len_index = len(csv_datas)

                csv_datas.append(data)
            except Exception as e:
                print(f"Error processing file '{file_path}': {e}")
                continue

    # now that all csv files have been processed, we can check data of each series to determine the min, avg and max values
    min_data = {
        "Time": [],
        "Power_per_FPS": []
    }
    avg_data = {
        "Time": [],
        "Power_per_FPS": []
    }
    max_data = {
        "Time": [],
        "Power_per_FPS": []
    }


    # loop through all series and for each "time" value, set the min, avg and max values
    for i in range(min_data_len):
        a = csv_datas[min_data_len_index]
        b = a["Time"]
        c = b[i]


        tim_at_i = c
        min_data["Time"].append(tim_at_i)
        avg_data["Time"].append(tim_at_i)
        max_data["Time"].append(tim_at_i)

        all_power_per_fps = [csv_datas[j]["Power_per_FPS"][i] for j in range(len(csv_datas))]
        min_data["Power_per_FPS"].append(min(all_power_per_fps))
        avg_data["Power_per_FPS"].append(sum(all_power_per_fps) / len(csv_datas))
        max_data["Power_per_FPS"].append(max(all_power_per_fps))

    # -------------------------
    # Create the plot
    # -------------------------
    min_data = pd.DataFrame(min_data)
    avg_data = pd.DataFrame(avg_data)
    max_data = pd.DataFrame(max_data)

    # - Applying rolling window to smooth the data
    # Rolling window of 5, centered around each point
    min_data['Smoothed'] = min_data['Power_per_FPS'].rolling(window=rw, center=True).mean()
    min_data['Smoothed'] = min_data['Smoothed'].bfill().ffill()
    avg_data['Smoothed'] = avg_data['Power_per_FPS'].rolling(window=rw, center=True).mean()
    avg_data['Smoothed'] = avg_data['Smoothed'].bfill().ffill()
    max_data['Smoothed'] = max_data['Power_per_FPS'].rolling(window=rw, center=True).mean()
    max_data['Smoothed'] = max_data['Smoothed'].bfill().ffill()



    # - Creating the plot
    plt.figure(figsize=(10, 6))
    # Plot both the original and the smoothed data for comparison
    plt.plot(min_data['Time'], min_data['Smoothed'], label='min Joule/Frame (Smoothed)', linewidth=1, color='green')
    plt.plot(avg_data['Time'], avg_data['Smoothed'], label='avg Joule/Frame (Smoothed)', linewidth=1, color='lightblue')
    plt.plot(max_data['Time'], max_data['Smoothed'], label='max Joule/Frame (Smoothed)', linewidth=1, color='purple')
    # empty plot to add the rolling window size to the legend
    plt.plot([], [], ' ', label=f"Rolling Window: {rolling_window}")
    plt.plot([], [], ' ', label=f"Amount of series: {len(csv_datas)}")

    plt.xlabel('Time (s)')
    plt.ylabel('Joule/Frame')
    plt.title(plot_title)
    plt.legend()
    plt.grid(True)

    # Build the output path to the desktop (works on most systems)
    output_filename = f"{plot_title}_benchmark_chart_rw{rolling_window}.png"
    output_path = os.path.join(path, output_filename)

    # Save the figure
    plt.savefig(output_path)
    print(f"Plot saved to {output_path}")

    #export the min, avg and max values to a csv file
    out_csv = []
    for i in range(min_data_len):
        out_csv.append({
            "Time": min_data["Time"][i],
            "MinJPF": min_data["Smoothed"][i],
            "AvgJPF": avg_data["Smoothed"][i],
            "MaxJPF": max_data["Smoothed"][i]
        })

    output_filename = f"{plot_title}_benchmark_data.csv"
    output_path = os.path.join(path, output_filename)
    # Open a file in write mode.
    with open(output_path, 'w') as file:
        headers = ["Time", "MinJPF", "AvgJPF", "MaxJPF"]

        writer = csv.DictWriter(file, fieldnames=headers)
        writer.writeheader()
        for row in out_csv:
            writer.writerow(row)

    print(f"Data exported to {output_path}")

if __name__ == '__main__':
    # Usage examples:
    #   1. Process a single file with a custom rolling window:
    #      python auto_plotter.py -rw=5 path/to/file.csv
    #
    #   1.bis Process a single file with the default rolling window (see DEFAULT_ROLLING_WINDOW):
    #      python auto_plotter.py path/to/file.csv
    #
    #   2. Process all CSV files in a directory with a custom rolling window:
    #      python auto_plotter.py -rw=5 -d path/to/directory
    #
    #   2.bis Process all CSV files in a directory with default rolling window:
    #      python auto_plotter.py -d path/to/directory
    #
    #   5. Process N CSV files in a directory and build a unique plot with min, avg and max values curves + export to a single csv file
    #      python auto_plotter.py -b path/to/directory
    #   5.bis Process N CSV files in a directory and build a unique plot with min, avg and max values curves + export to a single csv file with a custom rolling window:
    #      python auto_plotter.py -rw=5 -b path/to/directory

    # Set default values
    rolling_window = DEFAULT_ROLLING_WINDOW

    # Get all arguments (excluding the script name)
    args = sys.argv[1:]
    if not args:
        print("Missing arguments!")
        print_usage()
        sys.exit(1)

    # Display the help message
    if args[0] == "-h":
        print_help()
        sys.exit(0)

    # Check if the first argument is the rolling window flag
    if args[0].startswith("-rw="):
        try:
            rolling_window = int(args[0].split("=")[1])

        except ValueError:
            print("Invalid rolling window size. Must be an integer.")
            print_usage()
            sys.exit(1)

        args = args[1:]

    # Check the action flag
    action = "single"

    if args and args[0] == "-d":
        action = "directory"
        args = args[1:]

    if args and args[0] == "-b":
        action = "benchmark"
        args = args[1:]

    # The remaining argument should be the path
    if not args:
        print("Missing path argument!")
        print_usage()
        sys.exit(1)

    target_path = args[0]

    # Process directory or single file based on the flag
    if action == "directory":
        handle_directory(target_path, rolling_window)
    elif action == "benchmark":
        handle_benchmark(target_path, rolling_window)
    elif action == "single":
        handle_single_file(target_path, rolling_window)
    else:
        print("Invalid action!")
        print_usage()
        sys.exit(1)
